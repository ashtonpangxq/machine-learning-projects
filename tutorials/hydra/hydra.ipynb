{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b>Tutorial 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review of the Script:\n",
    "\n",
    "- omegaconf is installed by default with hydra. It is only used to provide the type annotation for cfg argument in func.\n",
    "- @hydra.main(config_path=\"config\", config_name=\"config\") This is the main decorator function that is used when any function requires contents from a configuration file.\n",
    "- Current working directory is changed. main.py exists in src/main.py but the output shows the current working directory is src/outputs/2021-03-13/16-22-21. This is the most important point when using Hydra. An explanation follows below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How Hydra handles different runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever a program is executed using python main.py, Hydra will create a new folder in outputs directory with the following naming scheme outputs/YYYY-mm-dd/HH-MM-SS i.e. the date and time at which the file was executed. Think about this for a second. Hydra provides you a way to maintain a log of every run without you having to worry about it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "src\n",
    "├── config\n",
    "│   └── config.yaml\n",
    "├── main.py\n",
    "├── outputs\n",
    "│   └── 2021-03-13\n",
    "│       └── 17-14-24\n",
    "│           ├── .hydra\n",
    "│           │   ├── config.yaml\n",
    "│           │   ├── hydra.yaml\n",
    "│           │   └── overrides.yaml\n",
    "│           ├── main.log\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens actually? When you run src/main.py, hydra moves this file to src/outputs/2021-03-13/16-22-21/main.py and then runs it. \n",
    "\n",
    "- You can verify this by checking the output of os.getcwd() as shown in the above example. \n",
    "- This means if your main.py relied on some external file, say test.txt, then you would have to use ../../../test.txt instead, as you are no longer running the program in src directory. \n",
    "- This also means that everything you save to disk would be saved relative to src/outputs/2021-03-13/16-22-21/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hydra provides two utility functions to handle this situation\n",
    "\n",
    "- <b>hydra.utils.get_original_cwd()</b>: Get the original current working directory i.e. `src`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "orig_cwd = hydra.utils.get_original_cwd()\n",
    "path = f\"{orig_cwd}/test.txt\"\n",
    "# path = src/test.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>hydra.utils.to_absolute_path(file_name):</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "path = hydra.utils.to_absolute_path('test.txt')\n",
    "\n",
    "# path = src/test.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to read src/test.txt and write the output to output.txt. The corresponding function to do this would be as shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "@hydra.main(config_path=\"config\", config_name=\"config\")\n",
    "def func(cfg: DictConfig):\n",
    "    orig_cwd = hydra.utils.get_original_cwd()\n",
    "\n",
    "    # Read file\n",
    "    path = f\"{orig_cwd}/test.txt\"\n",
    "    with open(path, \"r\") as f:\n",
    "        print(f.read())\n",
    "\n",
    "    # Write file\n",
    "    path = f\"output.txt\"\n",
    "    with open(path, \"w\") as f:\n",
    "        f.write(\"This is a dog\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the above code, we check the directory structure again:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "src\n",
    "├── config\n",
    "│   └── config.yaml\n",
    "├── main.py\n",
    "├── outputs\n",
    "│   └── 2021-03-13\n",
    "│       └── 17-14-24\n",
    "│           ├── .hydra\n",
    "│           │   ├── config.yaml\n",
    "│           │   ├── hydra.yaml\n",
    "│           │   └── overrides.yaml\n",
    "│           ├── main.log\n",
    "│           └── output.txt\n",
    "└── test.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file was written to the folder created by hydra. \n",
    "\n",
    "- This is a good way to save intermediate results when you are developing something. \n",
    "- You can use this feature to save the accuracy results of your model with different hyperparameters. \n",
    "- Now you do not have to spend time on manually saving the configuration file or the command line arguments you used to run the script and creating a new folder for each run to store the outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`As of newest version of Hydra, it will no longer change working directory at job runtime by default.`\n",
    "- `Include version_base=None`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contents of Subfolder in Outputs Folder (Hydra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each subfolder have the following substructure:\n",
    "\n",
    "```\n",
    "src/outputs/2021-03-13/17-14-24/\n",
    "├── .hydra\n",
    "│   ├── config.yaml\n",
    "│   ├── hydra.yaml\n",
    "│   └── overrides.yaml\n",
    "└── main.log\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `config.yaml` - Copy of the config file passed to the function (It doesn't matter if you pass foo.yaml, this file would still be named config.yaml)\n",
    "- `hydra.yaml` - Copy of the hydra config file. We will later see how to change some of the defaults used by hydra. (You can specify the message of python main.py --help here)\n",
    "- `overrides.yaml` - Copy of any argument that you provide through the command line and which changes one of the default value would be stored here\n",
    "- `main.log` - Output of the logger would be stored here. (For foo.py this file would be named foo.log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to use Logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Hydra, you can easily use the logging package provided by Python in your code without any setup. The output of the log is stored in main.log. A usage example is shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import logging\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "@hydra.main(config_path=\"config\", config_name=\"config\")\n",
    "def main_func(cfg: DictConfig):\n",
    "    log.debug(\"Debug level message\")\n",
    "    log.info(\"Info level message\")\n",
    "    log.warning(\"Warning level message\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The log of `python main.py` in this case would be (in `main.log`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "[2021-03-13 17:36:06,493][__main__][INFO] - Info level message\n",
    "[2021-03-13 17:36:06,493][__main__][WARNING] - Warning level message\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to include `DEBUG` also, then override `hydra.verbose=true` or `hydra.verbose=__main__` (i.e. `python main.py hydra.verbose=true`). The output in `main.log` in this case would be:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "[2021-03-13 17:36:38,425][__main__][DEBUG] - Debug level message\n",
    "[2021-03-13 17:36:38,425][__main__][INFO] - Info level message\n",
    "[2021-03-13 17:36:38,425][__main__][WARNING] - Warning level message\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick OmegaConf Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OmegaCong is a YAML-based hierarchical configuration system, with support for merging configurations from multiple sources (files, CLI argument, environment variables). You just need to know YAML to use Hydra. OmegaConf is used by Hydra in the background to handle everything for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example:\n",
    "\n",
    "```\n",
    "server:\n",
    "  ip: \"127.0.0.1\"\n",
    "  port: ???       # Missing value. Must be provided at command line\n",
    "  address: \"${server.ip}:${server.port}\" # String interpolation\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In main.py, you can access the server address as follows:\n",
    "\n",
    "```\n",
    "@hydra.main(config_path=\"config\", config_name=\"config\")\n",
    "def main_func(cfg: DictConfig):\n",
    "    server_address = cfg.server.address\n",
    "    print(f\"The server address = {server_address}\")\n",
    "\n",
    "\n",
    "# python main.py server.port=10\n",
    "# The server address = 127.0.0.1:10\n",
    "```\n",
    "\n",
    "As you can guess from the above example, if you want some variable to take the same value as another variable you should use the following syntax address:${server.ip}. We will later see some interesting use cases of this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Hydra for ML Projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the following `src` directory structure:\n",
    "\n",
    "```\n",
    "src\n",
    "├── config\n",
    "│   └── config.yaml\n",
    "└── main.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every ML project begins by collecting data and creating a dataset. When working on an image classification project, we use many different datasets like ImageNet, CIFAR10, and more. And each of these datasets will have different hyperparameters associated with them like: \n",
    "- batch size\n",
    "- the size of input images\n",
    "- the number of classes\n",
    "- the number of layers of the model to use for a particular dataset, and many more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 4 files involved in this example are:\n",
    "\n",
    "- `src/main.py`\n",
    "- `src/config/config.yaml`\n",
    "- `src/config/dataset/dataset1.yaml`\n",
    "- `src/config/dataset/dataset2.yaml`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "### src/main.py ###\n",
    "\n",
    "import torch\n",
    "import hydra\n",
    "from omegaconf import DictConfig\n",
    "\n",
    "@hydra.main(config_path=\"config\", config_name=\"config.yaml\")\n",
    "def get_dataset(cfg: DictConfig):\n",
    "    name_of_dataset = cfg.dataset.name\n",
    "    num_samples = cfg.num_samples\n",
    "    \n",
    "    if name_of_dataset == \"dataset1\":\n",
    "        feature_size = cfg.dataset.feature_size\n",
    "        x = torch.randn(num_samples, feature_size)\n",
    "        print(x.shape)\n",
    "        return x\n",
    "\n",
    "    elif name_of_dataset == \"dataset2\":\n",
    "        dim1 = cfg.dataset.dim1\n",
    "        dim2 = cfg.dataset.dim2\n",
    "        x = torch.randn(num_samples, dim1, dim2)\n",
    "        print(x.shape)\n",
    "        return x\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"You outplayed the developer\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    get_dataset()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corresponding Config Files:\n",
    "\n",
    "```\n",
    "### src/config/config.yaml\n",
    "defaults:\n",
    "  - dataset: dataset1\n",
    "\n",
    "num_samples: 2\n",
    "\n",
    "### src/config/dataset/dataset1.yaml\n",
    "\n",
    "# @package _group_\n",
    "name: dataset1\n",
    "feature_size: 5\n",
    "### src/config/dataset/dataset1.yaml\n",
    "\n",
    "# @package _group_\n",
    "name: dataset2\n",
    "dim1: 10\n",
    "dim2: 20\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is pretty much what we need to use Hydra in our projects. \n",
    "\n",
    "- In `src/main.py`, you will see that there are some common variables, namely `cfg.dataset` and `cfg.num_samples` that are shared across all the datasets. These are defined in the main config file that we pass to hydra using the command `@hydra.main(...)`.\n",
    "- Next, we need to define some variables specific to every dataset (like the number of classes in ImageNet and CIFAR10). To achieve this in hydra, we use the following syntax:\n",
    "\n",
    "```\n",
    "defaults:\n",
    "    - dataset: dataset1\n",
    "```\n",
    "\n",
    "- Here `dataset` is the name of the folder that will contain all the corresponding yaml files for each dataset (i.e. `dataset1` and `dataset2` in our case). So the directory structure would look something like this:\n",
    "\n",
    "```\n",
    "config\n",
    "  ├── config.yaml\n",
    "  └── dataset\n",
    "      ├── dataset1.yaml\n",
    "      └── dataset2.yaml\n",
    "```\n",
    "\n",
    "- And that is it. Now you can define the variables specific to every dataset in each of the above files, independent of each other.\n",
    "- These are called `config groups`. Every config file is independent of other config files in the folder and we can only choose one of the config files. To define these config groups you need to include a special comment at the beginning of every file `# @package _group_`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We can only choose one config file out of dataset1.yaml and dataset2.yaml as the value of dataset. And to tell hydra that these are config groups, we need to include the special comment `# @package _group_` at the start of these files.\n",
    "\n",
    "> Note: In Hydra 1.1, `_group_` will become the default package and there will be no need to add the special comment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is defaults? In our main config file, we need some way to distinguish normal string values from config group values. Like in this case, we want `dataset: dataset1` to be interpreted as a config group value rather than a string value. To do this we define all the config groups in `defaults`. And as you guessed it you provide a default value to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: defaults takes a list as input, so you need to start every name with a -."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output of code:\n",
    "\n",
    "```\n",
    "> python dataset.py\n",
    "torch.Size([2, 5])\n",
    "```\n",
    "\n",
    "```\n",
    "> python dataset.py dataset=dataset2\n",
    "torch.Size([2, 10, 20])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Hyperparameter values in Hydra Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use this same technique to define hyperparameter values for all your optimizers. Just create a new folder called optimizer and write `sgd.yaml`, `adam.yaml` files. And in the main `config.yaml`, you only need to add one more line:\n",
    "\n",
    "```\n",
    "defaults:\n",
    "    - dataset: dataset1\n",
    "    - optimizer: adam\n",
    "```\n",
    "\n",
    "and you use this to also create config files for `learning rate schedulers`, `models`, `evaluation metrics`, and almost everything else without having to actually hard code any of these values in the main codebase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one special case that you also need to know. What if you want your ResNet model to have different number of layers when using ImageNet vs CIFAR10. The naive solution would be to add if-else conditions in your model definition for every dataset, but that is a bad choice. What if tomorrow you add a new dataset. Now you would have to modify your model if-else condition to handle this new dataset. So instead we define a value num_layers in the config file and then we can use this value to create how every many layers we want.\n",
    "\n",
    "Suppose we use two models, resnet and vgg. Based on the discussion in the previous topic, we would have a separate config file for each model. The directory structure of the config folder would be:\n",
    "\n",
    "```\n",
    "config\n",
    "├── config.yaml\n",
    "├── dataset\n",
    "│   ├── cifar10.yaml\n",
    "│   └── imagenet.yaml\n",
    "└── model\n",
    "    ├── resnet.yaml\n",
    "    └── vgg.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now suppose we want the resnet model to have 34 layers when using CIFAR10 and 50 layers for every other dataset. In this case the config/model/resnet.yaml file would be:\n",
    "\n",
    "```\n",
    "# @package _group_\n",
    "name: resnet\n",
    "num_layers: 50 # As 50 is the default value\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to set the value num_layers=34 when the user specifies CIFAR10 dataset. To do this we can define a new config group in which we can define all the combinations of the special cases. In the main config/config.yaml we would make the following changes:\n",
    "\n",
    "```\n",
    "defaults:\n",
    "  - dataset: imagenet\n",
    "  - model: resnet\n",
    "  - dataset_model: ${defaults.0.dataset}_${defaults.1.model}\n",
    "    optional: true\n",
    "```\n",
    "\n",
    "Here we created a new config group named `dataset_model` that takes the value specified by dataset and model (like imagenet_resnet, cifar10_resnet). This is some weird syntax as defaults is a list, so you need to specify index before the name i.e. `defaults.0.dataset`. Now we can define the config file in `dataset_model/cifar10_resnet.py`:\n",
    "\n",
    "```\n",
    "# @package _global_\n",
    "model:\n",
    "  num_layers: 5\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: Here we used `# @package _global_` instead of `# @package _group_`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "@hydra.main(config_path=\"config\", config_name=\"config\")\n",
    "def main_func(cfg: DictConfig):\n",
    "    print(f\"Num features = {cfg.model.num_layers}\")\n",
    "\n",
    "> python main.py dataset=imagenet\n",
    "Num features = 50\n",
    "> python main.py dataset=cifar10\n",
    "Num features = 34\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to specify `optional: true`, as without it we would need to specify all combinations of dataset and model (if a user enters a value of dataset and model such that we have no config file for that option, then Hydra will throw an error for missing config file)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Show Config File</b>\n",
    "\n",
    "Prints the config file that is being passed to a function without running the function. Usage `--cfg [OPTION]` Valid `OPTION` are:\n",
    "\n",
    "- `job`: Your config file\n",
    "- `hydra`: Hydra’s config\n",
    "- `all` : job + hydra\n",
    "\n",
    "For Example:\n",
    "\n",
    "```\n",
    "> python main.py --cfg job\n",
    "```\n",
    "\n",
    "```\n",
    "# @package _global_\n",
    "num_samples: 2\n",
    "dataset:\n",
    "  name: dataset1\n",
    "  feature_size: 5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Multirun</b>\n",
    "\n",
    "This is a very useful feature of Hydra. The main idea is you can run your model for different values of learning rate, different values of weight decay using a single command. An example is shown below:\n",
    "\n",
    "For Example:\n",
    "\n",
    "```\n",
    "❯ python main.py lr=1e-3,1e-2 wd=1e-4,1e-2 -m\n",
    "[2021-03-15 04:18:57,882][HYDRA] Launching 4 jobs locally\n",
    "[2021-03-15 04:18:57,882][HYDRA]        #0 : lr=0.001 wd=0.0001\n",
    "[2021-03-15 04:18:58,016][HYDRA]        #1 : lr=0.001 wd=0.01\n",
    "[2021-03-15 04:18:58,149][HYDRA]        #2 : lr=0.01 wd=0.0001\n",
    "[2021-03-15 04:18:58,275][HYDRA]        #3 : lr=0.01 wd=0.01\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hydra will run your script with all combinations of `lr` and `wd`. The output will be stored in a new folder called `multirun` (instead of `outputs`). This folder also follows the same syntax of storing the contents in a date and time subfolder. The directory structure after running the above command is shown below:\n",
    "\n",
    "```\n",
    "multirun\n",
    "└── 2021-03-15\n",
    "    └── 04-21-32\n",
    "        ├── 0\n",
    "        │   ├── .hydra\n",
    "        │   └── main.log\n",
    "        ├── 1\n",
    "        │   ├── .hydra\n",
    "        │   └── main.log\n",
    "        ├── 2\n",
    "        │   ├── .hydra\n",
    "        │   └── main.log\n",
    "        ├── 3\n",
    "        │   ├── .hydra\n",
    "        │   └── main.log\n",
    "        └── multirun.yaml\n",
    "```\n",
    "\n",
    "It is the same as outputs except four folders are created here for the run instead of one. You can check the documentation on different ways of specifying the value of the variables to run the script on (these are called __sweeps__).\n",
    "\n",
    "Also, this would run your script locally and sequentially. If you want to run your script in parallel across multiple nodes or run it on AWS, you can check the documentation for the following plugins:\n",
    "\n",
    "\n",
    "- [Joblib](https://hydra.cc/docs/plugins/joblib_launcher) — Uses [Joblib.Parallel](https://joblib.readthedocs.io/en/latest/parallel.html)\n",
    "- [Ray](https://hydra.cc/docs/plugins/ray_launcher) — Run jobs on AWS cluster or local cluster\n",
    "- [RQ](https://hydra.cc/docs/plugins/rq_launcher)\n",
    "- [Submitit](https://hydra.cc/docs/plugins/submitit_launcher)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Adding Color to Terminal</b>\n",
    "\n",
    "You can add color to the output of terminal output of Hydra by installing this plugin:\n",
    "\n",
    "```\n",
    "pip install hydra_colorlog --upgrade\n",
    "```\n",
    "\n",
    "and changing these defaults in config file:\n",
    "\n",
    "```\n",
    "defaults:\n",
    "  - hydra/job_logging: colorlog\n",
    "  - hydra/hydra_logging: colorlog\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Specify Help Message</b>\n",
    "\n",
    "You can check the logs of one of your runs (under .hydra/hydra.yaml and then going to help.template) to see the default help message printed by hydra. But you can modify that message in your main config file as follows:\n",
    "\n",
    "```\n",
    "### config.yaml\n",
    "hydra:\n",
    "  help:\n",
    "    template:\n",
    "      'This is the help message'\n",
    "```\n",
    "\n",
    "```\n",
    "> python main.py --help\n",
    "This is the help message\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Changing Output Directory Name</b>\n",
    "If you want something more specific, than the `DATE/TIME` naming scheme using by hydra to store the output of all your runs, you can specify the folder name at the command line:\n",
    "\n",
    "```\n",
    "python main.py hydra.run.dir=outputs/my_run\n",
    "OR\n",
    "python main.py lr=1e-2,1e-3 hydra.sweep.dir=multirun/my_run -m\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ml-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d11cf63e32315551b13583ddc00f3df54160744934301eae2b9a1ffa25a15800"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
